{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 8 - Self-Paced Practice: Building a Weather App UI\n",
    "\n",
    "**Objective:** Reinforce the vision-to-code skill by generating the UI for a common application: a mobile weather app.\n",
    "\n",
    "**Estimated Time:** 45 minutes\n",
    "\n",
    "**Introduction:**\n",
    "This lab provides more practice with the powerful vision-to-code workflow. You will use a clean screenshot of a weather application and a vision-capable LLM to generate the React and Tailwind CSS code to replicate it. This solidifies your ability to quickly turn visual designs into functional frontend components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "We'll set up our environment and ensure we are using a vision-capable model, which is essential for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_vision_completion, save_artifact, clean_llm_output\n",
    "from IPython.display import Image, display, Code\n",
    "\n",
    "# This lab requires a vision-capable model.\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "if not model_name or not client:\n",
    "    print(\"Could not set up a valid LLM client. Please check your .env file and utils.py configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Design Screenshot\n",
    "\n",
    "This is the design we want our AI agent to build. It's a clean, modern weather app interface. We will provide the URL to this image directly to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_app_url = \"https://i.imgur.com/4l0iG66.png\"\n",
    "display(Image(url=weather_app_url, width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â­ Deeper Dive: The \"Generate -> Critique -> Refine\" Workflow\n",
    "\n",
    "Getting a pixel-perfect UI from the first prompt is rare. A more effective and professional workflow involves a three-step loop:\n",
    "\n",
    "1.  **Generate:** Use a vision model to create the first draft of the code, just as you're doing in this lab. This gets you 80-90% of the way there in seconds.\n",
    "2.  **Critique:** Use a second AI agent (or your own eyes) to compare the generated UI to the original design. This is the \"UI/UX Critic\" agent from the core lab. Create a list of specific inconsistencies (e.g., \"The font size of the temperature is too small,\" \"The padding on the main container should be `p-8` instead of `p-6`\").\n",
    "3.  **Refine:** Go back to the AI with the original code and your list of critiques. Use a prompt like: `\"Please update the following React code to address these design feedback points...\"`. The AI can then make targeted changes to the code.\n",
    "\n",
    "This iterative process is much faster than manual development and allows you to quickly converge on a high-quality final product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Your Task\n",
    "\n",
    "Write a single, detailed prompt to generate the complete React and Tailwind CSS code that replicates the design in the screenshot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’¡ Pro-Tip: Prompting for Visual Accuracy\n",
    "\n",
    "To get the best results from a vision-to-code model, be as specific as possible in your prompt. Don't just say \"make it look like the image.\" Guide its attention:\n",
    "\n",
    "- **Specify the Tech Stack:** `\"Generate a React component using Tailwind CSS.\"`\n",
    "- **Mention Key Elements:** `\"Pay close attention to the gradient background, the large temperature display, and the layout of the weekly forecast.\"`\n",
    "- **Handle Icons:** Models can't create images. Tell it how to handle them. `\"For the weather icons (sun, clouds), use placeholder SVGs or icons from a library like lucide-react.\"` This prevents it from getting stuck or outputting broken image tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your prompt here, following the pro-tip above.\n",
    "weather_ui_prompt = f\"\"\"\n",
    "You are an expert frontend developer specializing in creating beautiful user interfaces with React and Tailwind CSS.\n",
    "\n",
    "Your task is to analyze the provided image of a mobile weather app UI and write the code for a single, self-contained React component that accurately replicates its design.\n",
    "\n",
    "**Key Requirements:**\n",
    "- Create a single functional React component named `WeatherApp`.\n",
    "- Use Tailwind CSS for all styling. Pay close attention to the blue-to-purple gradient background, font sizes, colors, and spacing.\n",
    "- For the weather icons (like the large sun and the smaller icons for the forecast), please use appropriate SVG icons from the `lucide-react` library (e.g., `<Sun />`, `<CloudSun />`, `<CloudRain />`). Assume `lucide-react` is installed.\n",
    "- The output should be only the raw, complete JSX code for the component.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Weather App UI Component ---\")\n",
    "if model_name and client:\n",
    "    generated_weather_ui_raw = get_vision_completion(weather_ui_prompt, weather_app_url, client, model_name, api_provider)\n",
    "    cleaned_code = clean_llm_output(generated_weather_ui_raw, language='jsx')\n",
    "    \n",
    "    display(Code(cleaned_code, language='jsx'))\n",
    "    save_artifact(cleaned_code, \"app/day8_sp_weather_ui.jsx\")\n",
    "else:\n",
    "    print(\"Skipping UI generation. Please configure a vision model and client.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Great job! This practice lab has further sharpened your vision-to-code skills. You can see how this technique can be applied to virtually any design to create a high-quality first draft of a UI in seconds, dramatically accelerating frontend development. You've also learned about the iterative 'Generate -> Critique -> Refine' workflow, a key strategy for achieving production-quality results with AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
