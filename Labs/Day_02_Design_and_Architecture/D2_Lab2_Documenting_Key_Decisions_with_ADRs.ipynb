{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 10:20:25,784 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "Of course. Here is a clean, reusable markdown template for an Architectural Decision Record (ADR).\n",
      "\n",
      "It includes all the requested sections with clear headings and placeholder text to guide users. You can copy and paste this directly into a file named `adr-template.md` in your project.\n",
      "\n",
      "---\n",
      "\n",
      "```markdown\n",
      "# [Short Title of the Architectural Decision]\n",
      "\n",
      "*   **Status:** [Proposed | Accepted | Deprecated | Superseded by ADR-XXX]\n",
      "*   **Date:** [YYYY-MM-DD]\n",
      "\n",
      "## Context\n",
      "\n",
      "[Describe the problem or issue that this decision addresses. This section should set the stage for the decision. What is the background? What are the technical, business, or operational constraints (the \"forces\") that are influencing this decision? For example:\n",
      "*   \"We need to improve the performance of our data ingestion pipeline.\"\n",
      "*   \"Our current authentication system does not support single sign-on (SSO), which is a new business requirement.\"\n",
      "*   \"The team has expertise in Go but not in Rust.\"\n",
      "*   \"We have a limited budget for new infrastructure.\"]\n",
      "\n",
      "## Decision\n",
      "\n",
      "[State the specific decision that was made. This should be a clear and concise statement. For example:\n",
      "*   \"We will adopt Apache Kafka as our primary message broker.\"\n",
      "*   \"We will implement authentication using the OAuth 2.0 protocol with Auth0 as the identity provider.\"\n",
      "*   \"We will build the new microservice in Go using the Gin framework.\"]\n",
      "\n",
      "Follow this with the rationale. Why was this option chosen over others? What alternatives were considered and why were they rejected? This is the most important part of the ADR.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "[Outline the consequences of this decision, both positive and negative. This helps future readers understand the trade-offs that were made. Consider the impact on the system, the team, and the stakeholders.]\n",
      "\n",
      "**Positive:**\n",
      "*   [e.g., \"Improved system scalability and fault tolerance.\"]\n",
      "*   [e.g., \"Faster development time for new features that rely on this component.\"]\n",
      "*   [e.g., \"Alignment with industry-standard security practices.\"]\n",
      "\n",
      "**Negative:**\n",
      "*   [e.g., \"Increased operational complexity due to the introduction of a new technology (Kafka).\"]\n",
      "*   [e.g., \"Requires team members to be trained on the new authentication flow.\"]\n",
      "*   [e.g., \"Higher monthly infrastructure costs.\"]\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate a markdown ADR template.\n",
    "adr_template_prompt = \"\"\"You are tasked with creating a markdown template for an Architectural Decision Record (ADR).\n",
    "\n",
    "An ADR is a document that captures an important architectural decision, along with its context and consequences.\n",
    "\n",
    "Please create a clean, reusable markdown template that includes the following sections:\n",
    "\n",
    "1. **Title** - A descriptive title for the architectural decision\n",
    "2. **Status** - The current status of the decision (e.g., Proposed, Accepted, Deprecated, Superseded)\n",
    "3. **Context** - A section describing the problem, forces, and relevant background that led to this decision\n",
    "4. **Decision** - A section describing the specific architectural decision that was made, with rationale\n",
    "5. **Consequences** - A section outlining both positive and negative outcomes of this decision\n",
    "\n",
    "Make sure the template is properly formatted in markdown, with clear headings and appropriate structure. Include placeholder text to guide future use of the template.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "Here is a technical comparison of PostgreSQL with pgvector and specialized vector databases for a new hire onboarding platform.\n",
      "\n",
      "### **1. PostgreSQL with pgvector extension**\n",
      "\n",
      "This approach integrates vector similarity search directly into a standard PostgreSQL relational database.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Pros (Advantages, Benefits, Strengths)**\n",
      "\n",
      "*   **Unified Data Store:** Your vectors, the content they represent (e.g., article text), and all associated metadata (e.g., author, creation date, topic tags) reside in a single database. This drastically simplifies the system architecture.\n",
      "*   **Simplified Operations & Maintenance:** You only have one database system to deploy, monitor, back up, and secure. If your team is already familiar with PostgreSQL, the operational overhead is minimal.\n",
      "*   **Powerful Hybrid Search:** This is a key advantage. You can combine traditional, exact-match SQL `WHERE` clauses with approximate nearest neighbor (ANN) vector searches in a single query. This allows for efficient pre-filtering.\n",
      "    *   *Example:* \"Find articles similar to X, but only from the 'Engineering' department and created in the last 6 months.\" This is very powerful and efficient, as the database filters the dataset *before* performing the expensive vector search.\n",
      "*   **ACID Compliance & Data Consistency:** Since it's all in one transactional database, you have strong guarantees. When you update an article, you can update its text and its vector embedding in a single, atomic transaction, eliminating data synchronization problems.\n",
      "*   **Mature Ecosystem:** You leverage the entire PostgreSQL ecosystem: robust clients, ORMs (Object-Relational Mappers), managed cloud offerings (like AWS RDS, Google Cloud SQL), and extensive community support.\n",
      "\n",
      "#### **Cons (Disadvantages, Limitations, Challenges)**\n",
      "\n",
      "*   **Performance at Extreme Scale:** While performant for many use cases, it may not match the raw query-per-second (QPS) or sub-millisecond latency of a specialized, in-memory database when dealing with hundreds of millions or billions of vectors.\n",
      "*   **Resource Contention:** The same server resources (CPU, RAM, I/O) are used for both standard database operations (e.g., user logins, writing logs) and computationally intensive vector searches. A heavy search workload could potentially impact the performance of other application queries.\n",
      "*   **Developing Feature Set:** pgvector is a rapidly developing extension. Specialized databases may offer more advanced features like vector quantization (product quantization) to reduce memory footprint or more tunable indexing parameters out of the box.\n",
      "\n",
      "#### **Technical Considerations**\n",
      "\n",
      "*   **Implementation Complexity:** Low. If you have an existing PostgreSQL database, it's as simple as running `CREATE EXTENSION pgvector;` and adding a `vector` column to a table. The main complexity lies in tuning the HNSW or IVFFlat index parameters.\n",
      "*   **Scalability:** Scales vertically very well (i.e., by using a more powerful server). Standard PostgreSQL horizontal scaling patterns (e.g., read replicas, sharding) apply, but can be complex to implement correctly for a stateful database. For vector search, performance is highly dependent on having enough RAM to hold the index and a portion of the vectors.\n",
      "*   **Cost Implications:** Can be very cost-effective, especially if you already have a PostgreSQL instance. Costs may increase if you need to scale up your instance with more RAM/CPU to handle the vector workload, but you are still only paying for one system.\n",
      "\n",
      "#### **Suitability for the New Hire Onboarding Use Case**\n",
      "\n",
      "**Excellent fit.** The dataset size (KB articles, FAQs) is likely to be in the thousands to low hundreds of thousands, a scale where pgvector excels. The ability to perform hybrid searches is a major benefit for this use case, allowing new hires to filter by topic, department, or role before finding semantically similar documents. The operational simplicity of a single database is a significant advantage for a typical application development team.\n",
      "\n",
      "### **2. Specialized Vector Databases (e.g., ChromaDB, Weaviate, Milvus, FAISS)**\n",
      "\n",
      "These are databases or libraries designed from the ground up for the single purpose of storing, indexing, and searching large quantities of vector embeddings at high speed.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Pros (Advantages, Benefits, Strengths)**\n",
      "\n",
      "*   **Peak Performance & Scalability:** This is their primary strength. They are built to handle massive datasets (billions of vectors) and high-throughput workloads with the lowest possible latency, often leveraging in-memory processing.\n",
      "*   **Designed for Horizontal Scaling:** Most specialized vector databases are architected to be distributed systems, making it easier to scale out across multiple machines as data and query volume grows.\n",
      "*   **Decoupled Resources:** The intensive vector search workload is isolated from your primary application database. This prevents resource contention and ensures that a spike in search traffic won't slow down other critical parts of your application.\n",
      "*   **Advanced AI/ML Features:** Often include specialized features tailored for MLOps workflows, such as more sophisticated indexing algorithms, automatic embedding generation (in some cases), and fine-grained tuning for recall-vs-performance trade-offs.\n",
      "\n",
      "#### **Cons (Disadvantages, Limitations, Challenges)**\n",
      "\n",
      "*   **Increased Architectural Complexity:** You must manage two separate data stores: your primary database (like PostgreSQL) for metadata and a vector database for embeddings. This introduces significant complexity.\n",
      "*   **Data Synchronization Challenges:** Keeping the data in your primary and vector databases consistent is a major challenge. If an article is deleted from your primary database, you need a reliable process (e.g., event sourcing, change data capture) to ensure the corresponding vector is also deleted from the vector database. Failure to do so leads to stale or incorrect search results.\n",
      "*   **Limited Querying Capabilities:** Filtering capabilities on metadata are often less powerful and flexible than a full SQL `WHERE` clause. Complex filtering may require fetching a large list of vector IDs and then performing a secondary query against your primary database, which is inefficient and adds latency.\n",
      "*   **Higher Operational Overhead:** Requires deploying, managing, monitoring, and backing up a second, distinct piece of infrastructure. The learning curve for your team will be steeper as they need to understand the new system's API and operational best practices.\n",
      "\n",
      "#### **Technical Considerations**\n",
      "\n",
      "*   **Implementation Complexity:** High. Involves setting up the vector database, integrating its SDK into your application, and building a robust data synchronization pipeline between your primary and vector databases.\n",
      "*   **Scalability:** This is their core design principle. They are built to scale horizontally to handle massive query and data volumes that would be challenging for a general-purpose database.\n",
      "*   **Cost Implications:** Can be higher. You are paying for a second managed service or the infrastructure to host it yourself. While open-source options like ChromaDB or FAISS are free, they still incur hosting and operational costs. Managed services (like Pinecone) offer simplicity but at a premium price.\n",
      "\n",
      "#### **Suitability for the New Hire Onboarding Use Case**\n",
      "\n",
      "**Likely overkill and potentially less suitable.** The extreme scalability and performance are not required for a typical knowledge base size. The added complexity of managing a second database and ensuring data synchronization introduces significant engineering overhead and potential points of failure. The less powerful metadata filtering makes it harder to build the precise, context-aware search experience a new hire would benefit from. This approach is better suited for applications where vector search is the core, massive-scale function, such as a large-scale e-commerce recommendation engine.\n",
      "\n",
      "### **Summary Comparison Table**\n",
      "\n",
      "| Factor | PostgreSQL with pgvector | Specialized Vector Databases |\n",
      "| :--- | :--- | :--- |\n",
      "| **Implementation Complexity** | **Low** (if already using Postgres) | **High** (requires a second system and data sync logic) |\n",
      "| **Operational Overhead** | **Low** (one system to manage) | **High** (two systems to manage, monitor, and back up) |\n",
      "| **Performance** | **Very Good** for small-to-large scale (<100M vectors) | **Excellent** for massive scale (billions of vectors) and high QPS |\n",
      "| **Data Integrity & Consistency** | **Strong** (ACID transactions for data and vectors) | **Challenging** (requires a robust sync mechanism) |\n",
      "| **Hybrid Search** | **Excellent** (powerful, efficient SQL `WHERE` clauses) | **Limited** (basic metadata filtering, often less efficient) |\n",
      "| **Scalability** | Good vertical scaling; complex horizontal scaling | Excellent horizontal scaling by design |\n",
      "| **Cost Implications** | **Lower** (leverages existing infrastructure) | **Higher** (cost of a second managed service or infrastructure) |\n",
      "| **Ecosystem & Support** | **Mature** (leverages vast PostgreSQL ecosystem) | **Emerging** (newer, more specialized community and tooling) |\n",
      "| **Best Fit for Use Case** | **High.** Simple, powerful, and cost-effective for the scale of an onboarding platform. | **Low.** Over-engineered, adds unnecessary complexity and synchronization challenges. |\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to research database options.\n",
    "db_research_prompt = \"\"\"Act as an unbiased research assistant tasked with providing a technical comparison of database options for semantic search.\n",
    "\n",
    "We are building a new hire onboarding platform that needs semantic search capabilities to help new employees find relevant knowledge base articles, FAQs, and onboarding content.\n",
    "\n",
    "Please compare and contrast the following two database approaches:\n",
    "\n",
    "1. **PostgreSQL with pgvector extension** - Using the widely-used PostgreSQL database with the pgvector extension to add vector similarity search capabilities\n",
    "\n",
    "2. **Specialized vector databases** - Using dedicated vector databases like ChromaDB or FAISS (Facebook AI Similarity Search)\n",
    "\n",
    "For each approach, please provide:\n",
    "- Pros (advantages, benefits, strengths)\n",
    "- Cons (disadvantages, limitations, challenges)\n",
    "- Technical considerations (complexity, scalability, maintenance)\n",
    "- Suitability for the new hire onboarding use case\n",
    "\n",
    "Please provide a balanced analysis that objectively weighs both options without bias toward either solution. Consider factors such as:\n",
    "- Implementation complexity\n",
    "- Operational overhead\n",
    "- Performance characteristics\n",
    "- Integration with existing systems\n",
    "- Learning curve\n",
    "- Scalability\n",
    "- Cost implications\n",
    "- Community support and maintenance\n",
    "\n",
    "Just output the comparison\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "# TODO: Write a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\"You are a Staff Engineer documenting a key architectural decision for a new hire onboarding platform.\n",
    "\n",
    "Using the following research analysis and ADR template, create a complete, formal Architectural Decision Record documenting the decision to use PostgreSQL with pgvector for semantic search capabilities.\n",
    "\n",
    "Research Analysis:\n",
    "{db_research_output}\n",
    "\n",
    "ADR Template:\n",
    "{adr_template}\n",
    "\n",
    "Instructions:\n",
    "1. Act as a Staff Engineer making a formal architectural decision\n",
    "2. Populate the ADR template with the following specific content:\n",
    "   - Title: Something like \"ADR 001: Use PostgreSQL with pgvector for Semantic Search\"\n",
    "   - Status: Accepted\n",
    "   - Date: Today's date\n",
    "   - Context: Describe the need for semantic search in the onboarding platform and the decision to be made\n",
    "   - Decision: Clearly state that we have chosen PostgreSQL with pgvector over specialized vector databases\n",
    "   - Rationale: Synthesize the key reasons from the research (hybrid search capabilities, unified data store, operational simplicity, ACID compliance, etc.)\n",
    "   - Consequences: List both positive and negative consequences based on the research\n",
    "\n",
    "3. Write in a professional, formal tone appropriate for architectural documentation\n",
    "4. Use specific technical details from the research analysis\n",
    "5. Make the document complete and ready for version control\n",
    "\n",
    "Generate the complete, populated ADR without any additional commentary.\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\")\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
