{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Self-Paced Practice: Agile Planning for a Library App\n",
    "\n",
    "**Objective:** Reinforce the concepts of Day 1 by applying them to a new problem. You will generate a complete set of user stories for a new application, focusing on crafting a single, effective prompt to achieve a complex task.\n",
    "\n",
    "**Estimated Time:** 45 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Practice is key to mastering AI-assisted development. This lab allows you to apply the skills you learned in the core labs—moving from a problem statement to structured requirements—on a new scenario. This will help solidify your understanding and prompting skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "As always, we start by setting up our environment. This cell adds the project root to the system path, ensuring that our `utils.py` script can be imported correctly, and then initializes the LLM client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 16:38:56,664 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-flash latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output\n",
    "\n",
    "# Initialize the LLM client. You can change the model here if you wish.\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The New Problem Statement\n",
    "\n",
    "Your new problem is for a different domain:\n",
    "\n",
    "> **\"A local library wants a simple mobile app to help its patrons track borrowed books and get recommendations for what to read next.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_problem_statement = \"A local library wants a simple mobile app to help its patrons track borrowed books and get recommendations for what to read next.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Your Task\n",
    "\n",
    "Your goal is to create a single, comprehensive prompt that generates a complete set of user stories for this new library app. This combines the skills from all three challenges of the core lab into one.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Construct a detailed prompt that instructs the LLM to act as an expert Product Owner for mobile applications.\n",
    "2.  The prompt should first ask the LLM to **internally brainstorm** features and personas based on the `library_problem_statement`.\n",
    "3.  Then, using its own brainstormed ideas as context, the LLM should generate a list of 5-7 user stories.\n",
    "4.  Each user story must include detailed acceptance criteria in Gherkin format (`Given/When/Then`).\n",
    "5.  The final output should be a single, clean **JSON array**.\n",
    "6.  Save the validated JSON output to `artifacts/day1_sp_library_user_stories.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⭐ Deeper Dive: Chain-of-Thought Prompting\n",
    "\n",
    "For complex tasks like this, you can significantly improve the quality of the LLM's output by using a technique called **Chain-of-Thought (CoT) prompting**. Instead of just asking for the final answer, you ask the model to \"think step-by-step\" first.\n",
    "\n",
    "In this lab, we're asking the model to *internally* brainstorm before creating the final JSON. This is a form of CoT. It forces the model to establish context and reasoning *before* committing to the structured output, which almost always leads to a more coherent and well-thought-out result.\n",
    "\n",
    "**Pro-Tip:** When you need a complex output, add a phrase like `\"First, think through the user personas and potential features. Then, based on your thoughts, create the final JSON output.\"` to your prompt. This simple instruction can make a world of difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating User Stories for Library App ---\n",
      "Successfully parsed LLM output as JSON.\n",
      "\n",
      "--- Sample User Story ---\n",
      "{\n",
      "  \"id\": 1,\n",
      "  \"persona\": \"Casual Reader\",\n",
      "  \"user_story\": \"As a Casual Reader, I want to see a list of all books I currently have borrowed, so that I can easily keep track of what I'm reading and their due dates.\",\n",
      "  \"acceptance_criteria\": [\n",
      "    \"Given I have logged in with my library account\",\n",
      "    \"When I navigate to the 'My Books' section\",\n",
      "    \"Then I should see a list of all books currently borrowed under my account, including title, author, and due date for each.\",\n",
      "    \"And I should see a visual indicator for books due soon (e.g., within 3 days).\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write your comprehensive prompt here. \n",
    "# Use the Chain-of-Thought principle discussed above.\n",
    "# Be very specific about the final JSON structure.\n",
    "library_stories_prompt = f\"\"\" \n",
    "You are an expert Product Owner specializing in mobile applications.\n",
    "\n",
    "Your task is to generate a detailed product backlog in JSON format for the following problem statement: '{library_problem_statement}'\n",
    "\n",
    "**Process:**\n",
    "1.  First, internally brainstorm potential user personas (e.g., Casual Reader, Student, Parent) and key features (e.g., Barcode Scanning, Due Date Reminders, Personalized Recommendations).\n",
    "2.  Based on your internal brainstorming, generate a list of 5-7 detailed user stories.\n",
    "\n",
    "**OUTPUT REQUIREMENTS:**\n",
    "- You MUST output a valid JSON array. Your response must begin with [ and end with ]. Do not include any text or markdown before or after the JSON array.\n",
    "- Each object in the array must represent a single user story.\n",
    "- Each object must have the following keys: 'id' (an integer), 'persona' (a string), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories for Library App ---\")\n",
    "json_output_str = get_completion(library_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "try:\n",
    "    cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "    library_stories_json = json.loads(cleaned_json_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    print(\"\\n--- Sample User Story ---\")\n",
    "    print(json.dumps(library_stories_json[0], indent=2))\n",
    "    \n",
    "    # Save the artifact\n",
    "    save_artifact(json.dumps(library_stories_json, indent=2), \"artifacts/day1_sp_library_user_stories.json\")\n",
    "\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    library_stories_json = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done. You have successfully applied the core requirement-gathering skills from Day 1 to a new problem. This ability to adapt your prompting strategy to different domains is a crucial skill for an AI-driven developer. You have also learned about Chain-of-Thought prompting, a powerful technique for improving the quality of complex AI generations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
