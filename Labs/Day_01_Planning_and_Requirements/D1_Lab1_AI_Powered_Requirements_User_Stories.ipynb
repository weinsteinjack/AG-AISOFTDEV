{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Estimated Time:** 90 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to the first hands-on lab of the AI-Driven Software Engineering Program! All great software projects begin with a clear understanding of the problem to be solved. In this lab, you will take on the role of a tech lead or product manager and use an LLM as a co-pilot to transform a simple, high-level problem into a set of well-defined, actionable requirements. This process is fundamental to ensuring that the team builds the *right* product.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "This initial block sets up our environment. It adds the project's root directory to the Python path, allowing us to import our custom `utils.py` script. We then initialize the connection to our Large Language Model (LLM).\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client for our chosen LLM.\n",
    "- `get_completion()`: To send a prompt to the LLM and get a response.\n",
    "- `save_artifact()`: To save our generated requirements to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "Every project starts with a problem. Our problem is a common one in many organizations:\n",
    "\n",
    "> **\"We need a tool to help our company's new hires get up to speed.\"**\n",
    "\n",
    "This statement is intentionally vague. Our job is to use the LLM to add structure and detail to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help our company's new hires get up to speed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Complete the following challenges in order. Each one builds upon the last, increasing in technical complexity and value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Task:** Use the LLM to brainstorm a list of potential features and user personas based on the problem statement.\n",
    "\n",
    "**Instructions:**\n",
    "1. Write a simple prompt that asks the LLM to brainstorm features for the onboarding tool.\n",
    "2. Write a second prompt to identify three distinct user personas who would use this tool.\n",
    "3. Run both prompts and review the markdown output.\n",
    "\n",
    "**Expected Quality:** The output should be a simple, readable markdown list of features and a description of the personas. This is a good first step but lacks the structure needed for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a string variable named 'features_prompt'.\n",
    "# This prompt should ask the LLM to brainstorm features based on the problem_statement.\n",
    "features_prompt = \"\"\" # Your prompt here \"\"\"\n",
    "\n",
    "print(\"--- Brainstorming Features ---\")\n",
    "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_features)\n",
    "\n",
    "# TODO: Create a string variable named 'personas_prompt'.\n",
    "# This prompt should ask the LLM to identify three user personas based on the problem_statement.\n",
    "personas_prompt = \"\"\" # Your prompt here \"\"\"\n",
    "\n",
    "print(\"\\n--- Identifying User Personas ---\")\n",
    "user_personas = get_completion(personas_prompt, client, model_name, api_provider)\n",
    "print(user_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Task:** Now, let's increase the value by generating structured, formal Agile User Stories.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a new, more sophisticated prompt.\n",
    "2. This prompt should instruct the LLM to act as a Senior Product Manager.\n",
    "3. It must use the brainstormed features and personas from the previous step as context.\n",
    "4. The key instruction is to generate a list of user stories, each with detailed acceptance criteria in Gherkin format (`Given/When/Then`).\n",
    "5. **Crucially, the prompt must demand the final output be a well-formed JSON array of objects.** Each object should represent a user story and have keys like `id`, `user_story`, `persona`, and `acceptance_criteria`.\n",
    "\n",
    "> **Tip:** If the LLM's output isn't perfect JSON, try making your prompt even more specific. You can tell it, 'Do not include any text before or after the JSON array. Your response must begin with [ and end with ].'\n",
    "\n",
    "**Expected Quality:** The output should not be markdown, but a clean, parsable JSON string. This is a significant step up in value, as a JSON artifact can be automatically processed by other systems (e.g., imported into Jira)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a detailed prompt string named 'json_user_stories_prompt'.\n",
    "# This prompt needs to instruct the LLM to act as a Senior Product Manager and convert the\n",
    "# brainstormed features and personas into a structured JSON array of user stories.\n",
    "# Tip: Be very specific about the required JSON format in your prompt instructions. Tell it what keys to use and what the data types should be.\n",
    "json_user_stories_prompt = f\"\"\" \n",
    "# Your detailed prompt here. Use the variables from the previous steps as context.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "# Let's try to parse the JSON to see if the LLM followed instructions\n",
    "try:\n",
    "    # The LLM might wrap the JSON in markdown fences (```json ... ```).\n",
    "    # We'll clean that up before parsing.\n",
    "    if '```' in json_output_str:\n",
    "        json_output_str = json_output_str.split('```')[1].lstrip('json').strip()\n",
    "    \n",
    "    user_stories_json = json.loads(json_output_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    \n",
    "    if user_stories_json:\n",
    "        print(\"\\n--- Sample User Story ---\")\n",
    "        print(json.dumps(user_stories_json[0], indent=2))\n",
    "    else:\n",
    "        print(\"JSON array is empty.\")\n",
    "\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    user_stories_json = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Task:** Now for the highest-value step. Instead of just looking at the JSON, we will programmatically validate it and save it as a formal project artifact. This ensures reliability and prepares the requirements for automated use in later stages of the SDLC.\n",
    "\n",
    "**Instructions:**\n",
    "1. Complete the `validate_and_save_stories` function below.\n",
    "2. The function should iterate through the list of stories.\n",
    "3. For each story, it must validate that the required keys are present and that the acceptance criteria list is not empty.\n",
    "4. If all stories are valid, it should save the data to `artifacts/day1_user_stories.json`.\n",
    "\n",
    "**Expected Quality:** A robust script that guarantees the integrity of our requirements artifact. The final output is a validated `day1_user_stories.json` file in the `artifacts` directory, ready to be used as a reliable input for Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # TODO: Implement the validation logic inside this function.\n",
    "    # 1. Loop through each story in the 'stories_data' list.\n",
    "    # 2. For each story, check if it contains all the 'required_keys'.\n",
    "    # 3. Also check if the 'acceptance_criteria' list is not empty.\n",
    "    # 4. If a story is invalid, print an error message and set 'all_stories_valid' to False.\n",
    "    #    (You can use 'continue' to skip to the next story).\n",
    "\n",
    "    # Your validation code here\n",
    "\n",
    "    if all_stories_valid:\n",
    "        print(\"\\nAll user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # TODO: Call the save_artifact function from utils.py to save the data.\n",
    "        # Remember to convert the Python list back to a JSON string using json.dumps().\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nValidation failed. Artifact not saved.\")\n",
    "\n",
    "# Run the validation on the JSON data from the previous step\n",
    "if 'user_stories_json' in locals() and user_stories_json:\n",
    "    validate_and_save_stories(user_stories_json)\n",
    "else:\n",
    "    print(\"Skipping validation as user_stories_json is empty or not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
