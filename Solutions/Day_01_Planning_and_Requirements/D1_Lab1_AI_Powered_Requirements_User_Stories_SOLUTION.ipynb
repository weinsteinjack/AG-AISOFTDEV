{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories (Solution)\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Introduction:**\n",
    "This notebook contains the complete solution for Lab 1. It demonstrates how to use an LLM to systematically break down a problem, generate structured requirements, and programmatically validate the output. Each step includes explanations of the code and the reasoning behind the prompts.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Purpose:** This initial block of code prepares our environment for the lab. It adds the project root to the system path to ensure our `utils.py` helper script can be imported, and then initializes the LLM API client.\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Libraries Explained:**\n",
    "- **`os`**, **`sys`**: Standard Python libraries for interacting with the file system and Python's path, ensuring our modules are discoverable.\n",
    "- **`json`**: A standard library for working with JSON data. We use `json.loads` to parse the LLM's text output into a Python dictionary or list, and `json.dumps` to format Python objects into a pretty-printed JSON string for saving.\n",
    "- **`utils`**: Our custom helper script. \n",
    "  - `setup_llm_client()`: Handles reading the `.env` file and initializing the API client.\n",
    "  - `get_completion()`: Simplifies the process of sending a prompt to the LLM and receiving a text response.\n",
    "  - `save_artifact()`: Ensures our project artifacts are stored consistently in the `artifacts` directory.\n",
    "  - `clean_llm_output()`: A new standardized function to remove markdown fences from LLM outputs.\n",
    "  - `prompt_enhancer()`: An advanced meta-prompt system that takes raw user input and optimizes it using prompt engineering best practices, including role assignment, context grounding, and structural organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output, recommended_models_table, prompt_enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Qwen/Qwen-Image | huggingface | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\n",
       "| Qwen/Qwen-Image-Edit | huggingface | âŒ | âŒ | âŒ | âœ… | âŒ | - | - |\n",
       "| black-forest-labs/FLUX.1-Kontext-dev | huggingface | âŒ | âŒ | âŒ | âœ… | âŒ | - | - |\n",
       "| claude-opus-4-1-20250805 | anthropic | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\n",
       "| claude-opus-4-20250514 | anthropic | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\n",
       "| claude-sonnet-4-20250514 | anthropic | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 100,000 |\n",
       "| codex-mini-latest | openai | âœ… | âŒ | âŒ | âŒ | âŒ | - | - |\n",
       "| dall-e-3 | openai | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\n",
       "| deepseek-ai/DeepSeek-V3.1 | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 128,000 | 100,000 |\n",
       "| gemini-1.5-flash | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 8,192 |\n",
       "| gemini-1.5-pro | google | âœ… | âœ… | âŒ | âŒ | âŒ | 2,000,000 | 8,192 |\n",
       "| gemini-2.0-flash-exp | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 8,192 |\n",
       "| gemini-2.0-flash-preview-image-generation | google | âŒ | âŒ | âœ… | âŒ | âŒ | 32,000 | 8,192 |\n",
       "| gemini-2.5-flash | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-flash-image-preview | google | âŒ | âŒ | âœ… | âŒ | âŒ | 32,768 | 32,768 |\n",
       "| gemini-2.5-flash-lite | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-pro | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 65,536 |\n",
       "| gemini-live-2.5-flash-preview | google | âŒ | âŒ | âŒ | âŒ | âŒ | 1,048,576 | 8,192 |\n",
       "| gpt-4.1 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 32,768 |\n",
       "| gpt-4.1-mini | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 32,000 |\n",
       "| gpt-4.1-nano | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 32,000 |\n",
       "| gpt-4o | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 128,000 | 16,384 |\n",
       "| gpt-4o-mini | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 128,000 | 16,384 |\n",
       "| gpt-5-2025-08-07 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 400,000 | 128,000 |\n",
       "| gpt-5-mini-2025-08-07 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 400,000 | 128,000 |\n",
       "| gpt-5-nano-2025-08-07 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 400,000 | 128,000 |\n",
       "| gpt-image-1 | openai | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\n",
       "| meta-llama/Llama-3.3-70B-Instruct | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 8,192 | 4,096 |\n",
       "| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 1,000,000 | 100,000 |\n",
       "| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 10,000,000 | 100,000 |\n",
       "| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 32,768 | 8,192 |\n",
       "| o3 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\n",
       "| o4-mini | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\n",
       "| stabilityai/stable-diffusion-3.5-large | huggingface | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\n",
       "| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 4,096 | 1,024 |\n",
       "| veo-3.0-fast-generate-preview | google | âŒ | âŒ | âŒ | âŒ | âŒ | 1,024 | - |\n",
       "| veo-3.0-generate-preview | google | âŒ | âŒ | âŒ | âŒ | âŒ | 1,024 | - |\n",
       "| whisper-1 | openai | âŒ | âŒ | âŒ | âŒ | âœ… | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\\n|---|---|---|---|---|---|---|---|---|\\n| Qwen/Qwen-Image | huggingface | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\\n| Qwen/Qwen-Image-Edit | huggingface | âŒ | âŒ | âŒ | âœ… | âŒ | - | - |\\n| black-forest-labs/FLUX.1-Kontext-dev | huggingface | âŒ | âŒ | âŒ | âœ… | âŒ | - | - |\\n| claude-opus-4-1-20250805 | anthropic | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\\n| claude-opus-4-20250514 | anthropic | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\\n| claude-sonnet-4-20250514 | anthropic | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 100,000 |\\n| codex-mini-latest | openai | âœ… | âŒ | âŒ | âŒ | âŒ | - | - |\\n| dall-e-3 | openai | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\\n| deepseek-ai/DeepSeek-V3.1 | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 128,000 | 100,000 |\\n| gemini-1.5-flash | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 8,192 |\\n| gemini-1.5-pro | google | âœ… | âœ… | âŒ | âŒ | âŒ | 2,000,000 | 8,192 |\\n| gemini-2.0-flash-exp | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 8,192 |\\n| gemini-2.0-flash-preview-image-generation | google | âŒ | âŒ | âœ… | âŒ | âŒ | 32,000 | 8,192 |\\n| gemini-2.5-flash | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 65,536 |\\n| gemini-2.5-flash-image-preview | google | âŒ | âŒ | âœ… | âŒ | âŒ | 32,768 | 32,768 |\\n| gemini-2.5-flash-lite | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 65,536 |\\n| gemini-2.5-pro | google | âœ… | âœ… | âŒ | âŒ | âŒ | 1,048,576 | 65,536 |\\n| gemini-live-2.5-flash-preview | google | âŒ | âŒ | âŒ | âŒ | âŒ | 1,048,576 | 8,192 |\\n| gpt-4.1 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 32,768 |\\n| gpt-4.1-mini | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 32,000 |\\n| gpt-4.1-nano | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 1,000,000 | 32,000 |\\n| gpt-4o | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 128,000 | 16,384 |\\n| gpt-4o-mini | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 128,000 | 16,384 |\\n| gpt-5-2025-08-07 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 400,000 | 128,000 |\\n| gpt-5-mini-2025-08-07 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 400,000 | 128,000 |\\n| gpt-5-nano-2025-08-07 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 400,000 | 128,000 |\\n| gpt-image-1 | openai | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\\n| meta-llama/Llama-3.3-70B-Instruct | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 8,192 | 4,096 |\\n| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 1,000,000 | 100,000 |\\n| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 10,000,000 | 100,000 |\\n| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 32,768 | 8,192 |\\n| o3 | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\\n| o4-mini | openai | âœ… | âœ… | âŒ | âŒ | âŒ | 200,000 | 100,000 |\\n| stabilityai/stable-diffusion-3.5-large | huggingface | âŒ | âŒ | âœ… | âŒ | âŒ | - | - |\\n| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | âœ… | âŒ | âŒ | âŒ | âŒ | 4,096 | 1,024 |\\n| veo-3.0-fast-generate-preview | google | âŒ | âŒ | âŒ | âŒ | âŒ | 1,024 | - |\\n| veo-3.0-generate-preview | google | âŒ | âŒ | âŒ | âŒ | âŒ | 1,024 | - |\\n| whisper-1 | openai | âŒ | âŒ | âŒ | âŒ | âœ… | - | - |'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_models_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM Client configured: Using 'google' with model 'gemini-2.5-pro'\n",
      "âœ… LLM Client configured: Using 'huggingface' with model 'deepseek-ai/DeepSeek-V3.1'\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "brainstormed_features_client, brainstormed_features_model_name, brainstormed_features_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "user_personas_client, user_personas_model_name, user_personas_api_provider = setup_llm_client(model_name=\"deepseek-ai/DeepSeek-V3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "We define our starting pointâ€”a simple, high-level problem statementâ€”as a Python variable. This makes it easy to reuse in multiple prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help our company's new hires get up to speed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Here are the complete solutions for each challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Explanation:**\n",
    "This first challenge demonstrates the power of prompt enhancement. We start with simple, raw prompts for brainstorming features and identifying user personas. However, instead of using these basic prompts directly, we pass them through our `prompt_enhancer` function, which applies advanced prompt engineering techniques to optimize them.\n",
    "\n",
    "The `prompt_enhancer` automatically:\n",
    "- Assigns appropriate expert personas (e.g., \"You are a Senior Product Manager\")\n",
    "- Provides structured context and grounding\n",
    "- Defines clear task instructions with assertive action verbs\n",
    "- Sets explicit output format expectations\n",
    "- Organizes the prompt with clear structural delimiters\n",
    "\n",
    "**Key Efficiency Features:**\n",
    "- We reuse the existing LLM clients that were already initialized, avoiding duplicate setup\n",
    "- Different models can be used for different tasks (e.g., Gemini for features, DeepSeek for personas)\n",
    "- The personas prompt includes the brainstormed features as context for better coherence\n",
    "\n",
    "This enhancement process transforms simple requests into highly optimized prompts that produce more focused, detailed, and useful outputs. The goal is to generate a broad set of high-quality ideas (features and personas) that will serve as the foundation for the more structured tasks to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHALLENGE 1: AI-POWERED REQUIREMENTS GENERATION\n",
      "============================================================\n",
      "\n",
      "--- STEP 1: ENHANCING FEATURES PROMPT ---\n",
      "âœ… LLM Client configured: Using 'openai' with model 'gpt-4o'\n",
      "Brainstorm Enhanced prompt\n",
      " <persona>\n",
      "You are an expert in human resources technology with a focus on developing onboarding tools for new hires.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "Your task is to brainstorm features for a new hire onboarding tool that will help new employees at a company get up to speed quickly. Consider the needs of both the new hires and the HR department. The tool should facilitate learning, integration, and productivity for new employees.\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "1. Think step by step about the onboarding process and the challenges new hires typically face.\n",
      "2. Consider innovative features that could address these challenges effectively.\n",
      "3. Generate a list of potential features that could be included in the onboarding tool.\n",
      "</instructions>\n",
      "\n",
      "<output_format>\n",
      "Provide the output as a simple markdown list.\n",
      "</output_format>\n",
      "\n",
      "--- STEP 2: GENERATING BRAINSTORMED FEATURES ---\n",
      "Here is a list of potential features for a new hire onboarding tool, categorized for clarity.\n",
      "\n",
      "### Pre-Boarding & Administrative Features\n",
      "*   **Digital Paperwork Portal:** Allows new hires to complete and e-sign all necessary documents (I-9, W-4, direct deposit, NDAs) before their first day.\n",
      "*   **Automated Provisioning Workflows:** Triggers tasks for IT (laptop setup, account creation), Facilities (desk assignment), and other departments as soon as an offer is accepted.\n",
      "*   **Personalized Welcome Portal:** A custom landing page for the new hire featuring a welcome video from their manager, team photos, a \"Day 1\" schedule, and practical info (dress code, office map, parking).\n",
      "*   **\"Meet the Team\" Section:** An interactive page with bios, photos, and fun facts about immediate team members and key contacts.\n",
      "*   **Pre-Start Date Swag Selection:** Allows new hires to choose their company swag (t-shirt size, etc.) and have it shipped to them before they start.\n",
      "\n",
      "### Learning & Development Features\n",
      "*   **Role-Specific Learning Paths:** Customizable tracks of training modules, videos, and reading materials based on the new hire's department, role, and seniority level.\n",
      "*   **Micro-learning Modules:** Bite-sized content (2-5 minute videos or interactive lessons) on topics like company history, core products, key software tools, and cultural values.\n",
      "*   **Gamified Quizzes and Knowledge Checks:** Short, engaging quizzes to reinforce learning and track comprehension of key information.\n",
      "*   **Centralized Knowledge Base:** An AI-powered, searchable repository for all company information, from the employee handbook and benefits guide to departmental wikis and process documents.\n",
      "*   **Compliance Training Tracker:** Automatically assigns and tracks completion of mandatory training (e.g., security awareness, harassment prevention) with automated reminders.\n",
      "\n",
      "### Social Integration & Culture Features\n",
      "*   **Automated Buddy/Mentor Matching:** Suggests and facilitates the pairing of a new hire with an experienced employee based on role, department, or shared interests.\n",
      "*   **Social \"Scavenger Hunt\":** A checklist of introductory tasks designed to encourage networking, such as \"Have a virtual coffee with someone from another department\" or \"Find and join our company's book club channel.\"\n",
      "*   **Integrated Communication Channels:** Suggests and provides easy-join links to relevant Slack/Teams channels, distribution lists, and Employee Resource Groups (ERGs).\n",
      "*   **Company Lingo Glossary:** A searchable \"dictionary\" of company-specific acronyms, project codenames, and jargon.\n",
      "*   **Automated Introduction Post:** A tool that helps new hires craft a self-introduction post for company-wide communication channels, using a simple template.\n",
      "\n",
      "### Productivity & Goal Setting Features\n",
      "*   **Collaborative 30-60-90 Day Plan:** A dynamic template where the new hire and their manager can co-create, track, and comment on initial performance goals and milestones.\n",
      "*   **Task Management & Checklists:** A clear, chronological checklist of all onboarding tasks, from setting up email signatures to completing the first project, with due dates and owners.\n",
      "*   **Manager Dashboard:** A dedicated view for managers to track their new hire's progress, access conversation guides for 1:1 check-ins, and receive prompts for key onboarding touchpoints.\n",
      "*   **Resource & Tool Hub:** A single-click directory providing access and login instructions for all essential software and platforms the employee will need.\n",
      "*   **Feedback & Pulse Surveys:** Automated, short surveys sent at key intervals (end of Week 1, 30 days, 90 days) to gather feedback on the onboarding experience and gauge employee sentiment.\n",
      "\n",
      "### HR & Analytics Features\n",
      "*   **Onboarding Analytics Dashboard:** Provides HR with insights into key metrics like time-to-complete tasks, training module success rates, new hire engagement scores, and feedback trends.\n",
      "*   **Customizable Journey Builder:** Allows HR admins to easily create and modify onboarding workflows and content for different roles, locations, or business units without needing technical support.\n",
      "*   **HRIS & ATS Integration:** Seamlessly syncs new hire data from the Applicant Tracking System (ATS) and pushes completed profile information to the Human Resources Information System (HRIS).\n",
      "*   **Offboarding Workflow Management:** A feature to repurpose the tool's logic for a smooth and consistent offboarding process when an employee leaves.\n",
      "\n",
      "--- STEP 3: ENHANCING PERSONAS PROMPT ---\n",
      "âœ… LLM Client configured: Using 'openai' with model 'gpt-4o'\n",
      "Personas Enhanced prompt\n",
      " ```plaintext\n",
      "<persona>\n",
      "You are an expert in Human Resources technology solutions, specializing in onboarding tools for corporate environments.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "The company is developing a comprehensive onboarding tool to help new hires acclimate quickly and efficiently. The tool includes a wide range of features categorized into Pre-Boarding & Administrative, Learning & Development, Social Integration & Culture, Productivity & Goal Setting, and HR & Analytics. The goal is to streamline the onboarding process, enhance new hire engagement, and provide valuable insights to HR teams.\n",
      "\n",
      "Key features include:\n",
      "- Digital Paperwork Portal for completing documents.\n",
      "- Automated Provisioning Workflows for IT and Facilities.\n",
      "- Personalized Welcome Portal with a welcome video and practical info.\n",
      "- Role-Specific Learning Paths and Micro-learning Modules.\n",
      "- Gamified Quizzes and Knowledge Checks.\n",
      "- Automated Buddy/Mentor Matching and Social \"Scavenger Hunt\".\n",
      "- Collaborative 30-60-90 Day Plan and Task Management.\n",
      "- Onboarding Analytics Dashboard and HRIS & ATS Integration.\n",
      "\n",
      "The task is to identify and describe three distinct user personas who would interact with this tool. Each persona should include their role and main goal in using the tool.\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "1. Analyze the provided features and determine the types of users who would benefit from them.\n",
      "2. Identify three distinct user personas who would interact with the onboarding tool.\n",
      "3. For each persona, describe their role within the company and their main goal in using the tool.\n",
      "4. Ensure that the personas cover a range of interactions with the tool, from new hires to HR managers.\n",
      "</instructions>\n",
      "\n",
      "<output_format>\n",
      "Provide the output as a bulleted list with each persona clearly defined. Include:\n",
      "- Persona Name\n",
      "- Role Description\n",
      "- Main Goal\n",
      "</output_format>\n",
      "```\n",
      "\n",
      "--- STEP 4: GENERATING USER PERSONAS ---\n",
      "Based on the provided features, here are three distinct user personas who would interact with the onboarding tool:\n",
      "\n",
      "*   **Persona Name:** New Hire (e.g., \"Emma Chen\")\n",
      "    *   **Role Description:** A recently hired employee, likely in their first few weeks at the company. They could be in any department (e.g., Engineering, Marketing, Sales) and are eager to get started, feel welcomed, and become productive as quickly as possible.\n",
      "    *   **Main Goal:** To navigate the onboarding process seamlessly, complete all necessary administrative tasks, quickly acquire the knowledge and tools needed to perform their role, and build a social network within the company to feel integrated and engaged.\n",
      "\n",
      "*   **Persona Name:** Hiring Manager (e.g., \"David Rodriguez\")\n",
      "    *   **Role Description:** A department lead or people manager (e.g., Director of Engineering, Marketing Manager) who has just hired a new team member. They are responsible for the new hire's success, productivity, and integration into their specific team.\n",
      "    *   **Main Goal:** To efficiently bring their new team member up to speed with minimal administrative overhead, provide clear role-specific goals and expectations, facilitate connections within the team, and track the new hire's progress to ensure a smooth and successful ramp-up to full productivity.\n",
      "\n",
      "*   **Persona Name:** HR Onboarding Specialist (e.g., \"Fatima Al-Jamil\")\n",
      "    *   **Role Description:** An HR professional responsible for managing and optimizing the entire onboarding program for the organization. They ensure compliance, coordinate with IT/Facilities, and are tasked with improving the new hire experience and measuring onboarding effectiveness.\n",
      "    *   **Main Goal:** To automate and streamline the onboarding workflow, ensure all administrative and compliance tasks are completed efficiently, gain data-driven insights into the onboarding process's effectiveness, and identify areas for improvement to enhance new hire engagement and retention.\n",
      "\n",
      "============================================================\n",
      "CHALLENGE 1 COMPLETED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Challenge 1: Brainstorming Features and User Personas\n",
    "print(\"=\" * 60)\n",
    "print(\"CHALLENGE 1: AI-POWERED REQUIREMENTS GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Enhance Features Prompt\n",
    "print(\"\\n--- STEP 1: ENHANCING FEATURES PROMPT ---\")\n",
    "raw_features_prompt = f\"Based on the problem statement: '{problem_statement}', brainstorm a list of potential features for a new hire onboarding tool. Format the output as a simple markdown list.\"\n",
    "\n",
    "enhanced_features_prompt = prompt_enhancer(raw_features_prompt)\n",
    "print(\"Brainstorm Enhanced prompt\\n\", enhanced_features_prompt)\n",
    "\n",
    "# Step 2: Generate Brainstormed Features\n",
    "print(\"\\n--- STEP 2: GENERATING BRAINSTORMED FEATURES ---\")\n",
    "brainstormed_features = get_completion(\n",
    "    enhanced_features_prompt,\n",
    "    brainstormed_features_client,\n",
    "    brainstormed_features_model_name,\n",
    "    brainstormed_features_api_provider\n",
    ")\n",
    "print(brainstormed_features)\n",
    "\n",
    "# Step 3: Enhance Personas Prompt\n",
    "print(\"\\n--- STEP 3: ENHANCING PERSONAS PROMPT ---\")\n",
    "raw_personas_prompt = f\"Based on the problem statement: '{problem_statement}' and the following brainstormed features: {brainstormed_features}, identify and describe three distinct user personas who would interact with this tool. For each persona, describe their role and main goal.\"\n",
    "\n",
    "enhanced_personas_prompt = prompt_enhancer(raw_personas_prompt)\n",
    "print(\"Personas Enhanced prompt\\n\", enhanced_personas_prompt)\n",
    "\n",
    "# Step 4: Generate User Personas\n",
    "print(\"\\n--- STEP 4: GENERATING USER PERSONAS ---\")\n",
    "user_personas = get_completion(\n",
    "    enhanced_personas_prompt,\n",
    "    user_personas_client,\n",
    "    user_personas_model_name,\n",
    "    user_personas_api_provider\n",
    ")\n",
    "print(user_personas)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHALLENGE 1 COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Explanation:**\n",
    "This challenge represents a significant increase in complexity and value. We are no longer asking for simple text; we are demanding a specific, structured data format (JSON). \n",
    "\n",
    "The prompt is carefully engineered:\n",
    "1.  **Persona:** `You are a Senior Product Manager...` tells the LLM the role it should adopt.\n",
    "2.  **Context:** We provide the previous outputs (`problem_statement`, `brainstormed_features`, `user_personas`) inside `<context>` tags to give the LLM all the necessary information.\n",
    "3.  **Format:** The `OUTPUT REQUIREMENTS` section is extremely explicit. It tells the LLM to *only* output JSON, defines the exact keys for each object, and specifies the format for nested data (like the array of Gherkin strings). This strictness is key to getting reliable, machine-readable output.\n",
    "4.  **Parsing:** The `try...except` block is a crucial step. It attempts to parse the LLM's string output into a Python list of dictionaries. If it succeeds, we know the LLM followed our instructions perfectly. If it fails, we print the raw output to help debug the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2: Generating Formal User Stories\n",
    "print(\"=60,\" \\\n",
    "\"CHALLENGE 2: GENERATING FORMAL USER STORIES\")\n",
    "\n",
    "raw_json_prompt = f\"\"\"\n",
    "You are a Senior Product Manager creating a product backlog for a new hire onboarding tool.\n",
    "\n",
    "Based on the following context:\n",
    "<context>\n",
    "Problem Statement: {problem_statement}\n",
    "Potential Features: {brainstormed_features}\n",
    "User Personas: {user_personas}\n",
    "</context>\n",
    "\n",
    "Your task is to generate a list of 5 detailed user stories.\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- You MUST output a valid JSON array. Your response must begin with [ and end with ]. Do not include any text or markdown before or after the JSON array.\n",
    "- Each object in the array must represent a single user story.\n",
    "- Each object must have the following keys: 'id' (an integer), 'persona' (a string from the personas), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
    "\"\"\"\n",
    "\n",
    "enhanced_json_prompt = prompt_enhancer(raw_json_prompt)\n",
    "print(\"JSON User Stories Enhanced prompt\\n\", enhanced_json_prompt)\n",
    "\n",
    "# Step 2: Initialize LLM client for JSON user stories\n",
    "print(\"\\n--- STEP 2: INITIALIZING LLM CLIENT FOR JSON USER STORIES ---\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "print(f\"Using model: {model_name} provider: {api_provider}\")\n",
    "\n",
    "# Step 3: Generate User Stories as JSON\n",
    "print(\"\\n--- STEP 3: GENERATING USER STORIES AS JSON ---\")\n",
    "# We set a lower temperature to encourage the LLM to stick to the requested format.\n",
    "json_output_str = get_completion(enhanced_json_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "print(f\"Raw LLM response length: {len(json_output_str)} characters\")\n",
    "print(\"First 200 characters of response:\")\n",
    "print(repr(json_output_str[:200]))\n",
    "\n",
    "# Attempt to parse the string output into a Python list.\n",
    "try:\n",
    "    # Use our new standardized cleaning function from utils.py\n",
    "    cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "    print(f\"\\nCleaned JSON length: {len(cleaned_json_str)} characters\")\n",
    "    \n",
    "    user_stories_json = json.loads(cleaned_json_str)\n",
    "    print(\"âœ… Successfully parsed LLM output as JSON.\")\n",
    "    print(f\"Number of user stories generated: {len(user_stories_json)}\")\n",
    "    \n",
    "    # Pretty-print the first user story to verify its structure\n",
    "    print(\"\\n--- Sample User Story ---\")\n",
    "    print(json.dumps(user_stories_json[0], indent=2))\n",
    "    \n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"âŒ Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"\\n--- DEBUGGING INFO ---\")\n",
    "    print(\"Raw LLM Output:\")\n",
    "    print(\"-\n",
    "50\n",
    ",\n",
    ",\n",
    "-\n",
    "50\n",
    ",\n",
    ",\n",
    "        print(\"-\n",
    "50\n",
    ",\n",
    ",\n",
    "-\n",
    "50\n",
    ",\n",
    ",\n",
    ",\n",
    "\\nâš ï¸  Set user_stories_json to empty list to prevent downstream errors.\")\n",
    "    print(\"   Please check the API key configuration and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Explanation:**\n",
    "This is the final and most critical step. We treat the LLM's output as untrusted input and subject it to programmatic validation. This ensures that the artifact we create is reliable and can be consumed by other automated tools in later stages of the SDLC without causing errors. \n",
    "\n",
    "The `validate_and_save_stories` function acts as a gatekeeper. It checks for the correct data types (a list of objects) and ensures that all required fields are present in each object. Only if all checks pass do we proceed to save the file using `save_artifact`. This creates a trustworthy `day1_user_stories.json` file that can be confidently used as an input for other automated processes in our SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return False\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # Loop through each story object in the list.\n",
    "    for i, story in enumerate(stories_data):\n",
    "        # Check for the presence of all required keys.\n",
    "        if not all(key in story for key in required_keys):\n",
    "            print(f\"Validation Failed: Story at index {i} is missing one or more required keys.\")\n",
    "            print(f\"   Expected keys: {required_keys}\")\n",
    "            print(f\"   Found keys: {list(story.keys()) if isinstance(story, dict) else 'Not a dictionary'}\")\n",
    "            all_stories_valid = False\n",
    "            continue # Don't bother with further checks for this invalid story\n",
    "        \n",
    "        # Check that the acceptance criteria is a list with at least one item.\n",
    "        ac = story.get('acceptance_criteria')\n",
    "        if not isinstance(ac, list) or not ac:\n",
    "            print(f\"Validation Failed: Story at index {i} (ID: '{story.get('id')}') has invalid or empty acceptance criteria.\")\n",
    "            print(f\"   Expected: list with at least one item\")\n",
    "            print(f\"   Found: {type(ac)} with value {ac}\")\n",
    "            all_stories_valid = False\n",
    "\n",
    "    # Only save the artifact if all stories in the list are valid.\n",
    "    if all_stories_valid:\n",
    "        print(f\"\\nâœ… All {len(stories_data)} user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # Use the helper function to save the file, creating the 'artifacts' directory if needed.\n",
    "        # We use json.dumps with an indent to make the saved file human-readable.\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\nâŒ Validation failed for one or more stories. Artifact not saved.\")\n",
    "        return False\n",
    "\n",
    "# Note: The actual validation call is now in the next cell with better error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check the current state of user_stories_json\n",
    "print(\"=== DIAGNOSTIC INFO ===\")\n",
    "if 'user_stories_json' in locals():\n",
    "    print(f\"user_stories_json exists: {type(user_stories_json)}\")\n",
    "    print(f\"Length: {len(user_stories_json) if hasattr(user_stories_json, '__len__') else 'N/A'}\")\n",
    "    if user_stories_json:\n",
    "        print(\"Sample content:\", user_stories_json[0] if len(user_stories_json) > 0 else \"Empty list\")\n",
    "    else:\n",
    "        print(\"user_stories_json is empty or falsy\")\n",
    "        print(\"This means JSON parsing likely failed in the previous cell.\")\n",
    "        print(\"Check the raw LLM output above for formatting issues.\")\n",
    "else:\n",
    "    print(\"user_stories_json variable does not exist\")\n",
    "    print(\"This means the previous cell never executed successfully\")\n",
    "\n",
    "# Also check if we have the raw output\n",
    "if 'json_output_str' in locals():\n",
    "    print(f\"\\nRaw LLM output length: {len(json_output_str)} characters\")\n",
    "    print(\"First 200 characters of raw output:\")\n",
    "    print(repr(json_output_str[:200]))\n",
    "else:\n",
    "    print(\"json_output_str not available\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the validation function on the data we parsed from the LLM.\n",
    "print(\"=== VALIDATION STEP ===\")\n",
    "\n",
    "if 'user_stories_json' not in locals():\n",
    "    print(\"âŒ ERROR: user_stories_json variable not found.\")\n",
    "    print(\"   Make sure to run the previous cell that generates user stories.\")\n",
    "elif not user_stories_json:\n",
    "    print(\"âŒ ERROR: user_stories_json is empty or None.\")\n",
    "    print(\"   This usually means JSON parsing failed in the previous step.\")\n",
    "    print(\"   Solutions:\")\n",
    "    print(\"   1. Check that your API keys are correctly configured\")\n",
    "    print(\"   2. Re-run the previous cell to generate user stories\")\n",
    "    print(\"   3. Examine the raw LLM output for formatting issues\")\n",
    "    \n",
    "    # Try to re-parse if we have the raw output\n",
    "    if 'json_output_str' in locals() and json_output_str.strip():\n",
    "        print(\"\\nğŸ”„ Attempting to re-parse the JSON...\")\n",
    "        try:\n",
    "            cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "            user_stories_json = json.loads(cleaned_json_str)\n",
    "            print(\"âœ… Re-parsing successful! Proceeding with validation...\")\n",
    "            validate_and_save_stories(user_stories_json)\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"âŒ Re-parsing failed: {e}\")\n",
    "            print(\"Raw output that failed to parse:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(json_output_str)\n",
    "            print(\"-\" * 50)\n",
    "else:\n",
    "    print(f\"âœ… Found user_stories_json with {len(user_stories_json)} stories\")\n",
    "    validate_and_save_stories(user_stories_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a function. that adds 2 numbers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
