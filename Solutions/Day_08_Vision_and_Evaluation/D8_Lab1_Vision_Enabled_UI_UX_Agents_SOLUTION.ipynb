{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42928672",
   "metadata": {},
   "source": [
    "# Day 8 - Lab 1: Vision-Enabled UI/UX Agents (Solution)\n",
    "\n",
    "**Objective:** Use multi-modal vision models to generate a frontend UI from a design image, and then use a second agent to perform an automated design review.\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete prompts and expected outputs for the vision-based frontend development lab. It demonstrates a full workflow from image-to-code, refactoring, and AI-powered design review.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678dec55",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Explanation:**\n",
    "This setup block is crucial. It ensures our helper utilities are importable and initializes the client for a specific vision-capable model. For this lab, a powerful multi-modal model like `gpt-4o` is required to accurately interpret the design image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c537f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_vision_completion, get_completion, save_artifact, clean_llm_output\n",
    "from IPython.display import Image, display, Code, Markdown\n",
    "\n",
    "# Ensure you select a vision-capable model\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "if not model_name:\n",
    "    print(\"Could not set up a valid LLM client. Please check your .env file and utils.py configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8c4a8",
   "metadata": {},
   "source": [
    "## Step 2: The Design Screenshot\n",
    "\n",
    "**Explanation:**\n",
    "We define the URL of the target design. This image will be the primary context for our vision-powered agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432fb6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/s42SYz6.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login_form_url = \"https://i.imgur.com/s42SYz6.png\"\n",
    "display(Image(url=login_form_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12dce1f",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392f1b0",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating a Monolithic UI Component\n",
    "\n",
    "**Explanation:**\n",
    "This prompt is a direct instruction to the vision model. We assign it the `persona` of an expert frontend developer. We provide the `context` (the image) and the `format` requirements (single React component, Tailwind CSS). This guides the model to produce a single, self-contained code block that replicates the design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cabb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ui_prompt = f\"\"\"\n",
    "You are an expert frontend developer specializing in React and Tailwind CSS.\n",
    "\n",
    "Your task is to analyze the provided image of a login form and write the code for a single, self-contained React component that accurately replicates its design and layout.\n",
    "\n",
    "**Requirements:**\n",
    "- Use functional components.\n",
    "- Use Tailwind CSS for all styling. Do not use custom CSS or style tags.\n",
    "- Make sure the component is accessible, using appropriate HTML tags and attributes.\n",
    "- The output should be only the raw JSX code for the component.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Monolithic UI Component ---\")\n",
    "generated_monolithic_code = \"\"\n",
    "if model_name:\n",
    "    generated_monolithic_code = get_vision_completion(generate_ui_prompt, login_form_url, client, model_name, api_provider)\n",
    "    cleaned_code = clean_llm_output(generated_monolithic_code, language='jsx')\n",
    "    display(Code(cleaned_code, language='jsx'))\n",
    "    save_artifact(cleaned_code, \"app/day8_login_monolithic.jsx\")\n",
    "else:\n",
    "    print(\"Skipping UI generation because no valid model is configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875cef3",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Refactoring into Reusable Components\n",
    "\n",
    "**Explanation:**\n",
    "This prompt focuses on code quality. We provide the previously generated code as context and ask the LLM to act as a senior developer who values clean, component-based architecture. The instruction to create smaller, reusable components like `<StyledButton>` and `<InputWithIcon>` guides the LLM to perform a specific, best-practice refactoring task. Note that this is a text-only task, so we use the standard `get_completion` helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "refactor_ui_prompt = f\"\"\"\n",
    "You are a senior frontend developer who champions clean, component-based architecture.\n",
    "\n",
    "The following React code is a single, monolithic component. Your task is to refactor it.\n",
    "\n",
    "**Refactoring Requirements:**\n",
    "1.  Create smaller, reusable sub-components where appropriate. For example, the button and the input fields are good candidates for their own components (e.g., `InputWithIcon`, `LoginButton`).\n",
    "2.  The final output should be a single file containing the definitions for the new, smaller components and the main `LoginForm` component that uses them.\n",
    "3.  Ensure the final visual output remains identical to the original.\n",
    "\n",
    "**Original Code:**\n",
    "```jsx\n",
    "{cleaned_code}\n",
    "```\n",
    "\n",
    "Output only the raw, complete, refactored JSX code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Refactoring UI into Components ---\")\n",
    "cleaned_refactored_code = \"\"\n",
    "if 'cleaned_code' in locals() and cleaned_code:\n",
    "    refactored_code = get_completion(refactor_ui_prompt, client, model_name, api_provider)\n",
    "    cleaned_refactored_code = clean_llm_output(refactored_code, language='jsx')\n",
    "    display(Code(cleaned_refactored_code, language='jsx'))\n",
    "    save_artifact(cleaned_refactored_code, \"app/day8_login_refactored.jsx\")\n",
    "else:\n",
    "    print(\"Skipping refactoring because monolithic code was not generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9cd4c",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): The AI UI/UX Critic Agent\n",
    "\n",
    "**Explanation:**\n",
    "This prompt demonstrates an AI-on-AI workflow for quality assurance. We give this new agent the persona of a meticulous UI/UX designer. Its task is to perform a comparative analysis. It receives two pieces of context: the original design `image` and the `code`. The prompt specifically asks it to compare the *likely rendered output* of the code to the design and list inconsistencies. This automates a tedious and subjective part of the development process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_prompt = f\"\"\"\n",
    "You are a meticulous UI/UX designer with a sharp eye for detail. Your task is to perform a design review.\n",
    "\n",
    "You will be given two things:\n",
    "1.  An image of the original design mockup.\n",
    "2.  The React code that was generated to implement that design.\n",
    "\n",
    "Your job is to compare the likely visual output of the code to the original design image. Identify and list any visual inconsistencies, no matter how small. Pay close attention to:\n",
    "- Spacing and padding\n",
    "- Font sizes and weights\n",
    "- Color hex codes\n",
    "- Border radius and shadows\n",
    "- Overall layout and alignment\n",
    "\n",
    "**Generated Code:**\n",
    "```jsx\n",
    "{cleaned_refactored_code}\n",
    "```\n",
    "\n",
    "Provide your feedback as a markdown-formatted list.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Invoking UI/UX Critic Agent ---\")\n",
    "if cleaned_refactored_code:\n",
    "    design_review = get_vision_completion(critic_agent_prompt, login_form_url, client, model_name, api_provider)\n",
    "    display(Markdown(design_review))\n",
    "    save_artifact(design_review, \"artifacts/design_review.md\")\n",
    "else:\n",
    "    print(\"Skipping critic agent because refactored code is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a4336",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Fantastic! You have completed a full, end-to-end frontend development workflow using multiple AI agents. You used a vision-powered agent to generate code from a design, a refactoring agent to improve the code's structure, and a critic agent to perform an automated design review. This powerful combination of skills can dramatically accelerate the process of turning visual ideas into functional user interfaces.\n",
    "\n",
    "> **Key Takeaway:** The workflow of **Generate -> Refactor -> Critique** is a powerful AI-assisted development pattern. Using specialized agents for each step allows you to rapidly create a first draft, improve its quality, and then automatically check it for correctness, significantly speeding up the iteration cycle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
